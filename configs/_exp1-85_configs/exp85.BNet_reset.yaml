# close to exp83
# + but different LR schedule to avoid such large difference at the end


name : exp85.BNet_reset
arch : BNet
model_params:
    stage_fns: ["simpl", "simpl", "simpl", "simpl"]
    block_fns: ["Pre_XX", "Pre_XX", "Pre_IR", "Pre_IR"]
    stage_args: [
        {"dim_reduction": "stride & expand", "bottle_ratio": 1, "force_residual": True},
        {"dim_reduction": "stride & expand", "bottle_ratio": 1, "force_residual": True},
        {"bottle_ratio": 1, "force_residual": True, "dw_str2_kernel_size": 9, "force_expansion": True},
        {"bottle_ratio": 1, "force_residual": True, "dw_str2_kernel_size": 9, "force_expansion": True},
    ]
    stem_width: 32
    head_width: 2560
    norm_act: leaky_relu
    stem_type: s2d
    layers: [1, 2, 6, 5]
    channels: [128, 192, 640, 1024]
    head_type: default

blur: true
cutmix: 1.0
weight_decay : 3e-5
smooth: true
ctwist: true
# very short period of ~3 epoch for ema: 0.9993 ** (2500 * 3) ~= 5e-3
ema_decay: 0.9993

# lr should be BS/256 * 0.1
# much smaller lr during 2nd stage for better convergence
phases : [
    {"ep": 0, "sz": 224, "bs": 256},
    {"ep": [0, 6], "lr": [0, 0.4], "mom": 0.95},
    {"ep": [6, 60], "lr": [0.4, 0], "mode": "cos"},
    {"ep": [60, 90], "lr": [0.01, 0], "mode": "cos"}, 
]
